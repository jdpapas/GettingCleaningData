zips <- xpathSApply(doc, "//row/zipcode='21231'", text)
zips
doc
zips <- xpathSApply(doc, "//zipcode", text)
zips <- xpathSApply(doc, "//zipcode", xmlValue)
zips
zips <- xpathSApply(doc, "//zipcode=21231", xmlValue)
zips <- xpathSApply(doc, "//zipcode", xmlValue)
zips <- xpathSApply(doc, "//zipcode[.='21231'", xmlValue)
zips <- xpathSApply(doc, "//zipcode[.='21231']", xmlValue)
zips
length(zips)
fileurl="https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileurl, destfile = "acs.csv", method="libcurl")
library(data.table)
install.packages(data.table)
"data.table"
install.packages("data.table")
library(data.table)
DT = data.table()
DT
?data.table
?fread
DT <- fread("acs.csv")
DT
str(DT)
head(DT)
sapply(split(DT$pwgtp15,DT$SEX),mean)
mean(DT$pwgtp15,by=DT$SEX)
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
DT[,mean(pwgtp15),by=SEX]
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
tapply(DT$pwgtp15,DT$SEX,mean)
?tapply
mean(DT$pwgtp15,by=DT$SEX)
DT[,mean(pwgtp15),by=SEX]
install.packages("RMySQL")
ucscDB <- dbConnect(MySQL(),user="genome",host="genome-mysql.cse.ucsc.edu")
load(RMySQL)
load.library(RMySQL)
load(RMySQL)
library(RMySQL)
ucscDB <- dbConnect(MySQL(),user="genome",host="genome-mysql.cse.ucsc.edu")
result <- dbGetQuery(ucscDB,"show databases;" dbDisconnect(ucscDB));
result <- dbGetQuery(ucscDB,"show databases;"; dbDisconnect(ucscDB));
result <- dbGetQuery(ucscDB,"show databases;"); dbDisconnect(ucscDB));
result <- dbGetQuery(ucscDB,"show databases;"); dbDisconnect(ucscDB);
result
hg19 <- dbConnect(MySQL(),user="genome", db="hg19", host="genome-mysql.cse.ucsc.edu")
alltables <- dbListTables(hg19)
length(alltables)
alltables[1:5]
dbListFields(hg19, "affyU133Plus2")
dbGetQuery(hg19, "select count(*) from affyU133Plus2")
affyData <- dbReadTable(hg19, "affyU133Plus2")
hg19 <- dbConnect(MySQL(),user="genome", db="hg19", host="genome-mysql.cse.ucsc.edu")
affyData <- dbReadTable(hg19, "affyU133Plus2")
head(affyData)
query <- dbSendQuery(hg19, "select * fron affyU133Plus2 where misMatches between 1 and 3")
query <- dbSendQuery(hg19, "select * from affyU133Plus2 where misMatches between 1 and 3")
affyMis <- fetch(query); quantile(affyMis$misMatches)
affyMisSmall <- fetch(qury, n=10); dbClearResult(query);
affyMisSmall <- fetch(query, n=10); dbClearResult(query);
dim(affyMisSmall)
dbDisconnect(hg19)
dbDisconnect(hg19)
source("http://bioconductor.org/biocLite.R")
biocLite("rhdf5")
library(rhdf5)
created = h5createFile("example.h5")
created
created = h5createGrou("example.h5", "foo")
created = h5createGroup("example.h5", "foo")
created = h5createGroup("example.h5", "baa")
created = h5createGroup("example.h5", "foo/foobaa")
h5ls("example.h5")
A = matrix(1:10,nr=5,nc=2)
h5write(A, "example.h5", "foo/A")
B=array(seq(0.1, 2.0,by=0.1),dim=c(5,2,2))
attr(B, "scale") <- "liter"
h2write(B, "example.h5", "foo/foobaa/B")
h5write(B, "example.h5", "foo/foobaa/B")
h5ls("example.h5")
df = data.frame(1L:5:, seq(0,1, length.out = 5), c("ab", "cde", "fghi", "a", "s"), stringsAsFactors=FALSE)
df = data.frame(1L:5L, seq(0,1, length.out = 5), c("ab", "cde", "fghi", "a", "s"), stringsAsFactors=FALSE)
h5write(df, "example.h5", "df")
h5ls("example.h5")
readA = h54read("example.h5", "foo/A")
readA = h5read("example.h5", "foo/A")
readB= h5read("example.h5", "foo/foobaa/B")
readdf = h5read("example.h5", "df")
readA
rreaddf
readdf
h5write(c(12,13,14),"example.h5", "foo/A", index=list(1:3,1))
h5read("example.h5", "foo/A")
con = url("http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
htmlCode=readline(con)
close(con)
htmlCode
con = url("http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
htmlCode=readline(con)
htmlCode=readLines(con)
htmlCode
close(con)
library(XML)
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url, useInternalNodes = T)
xpathSApply(html, "//title", xmlValue)
xpathSApply(html, "//td[@id='col-citedby']", xmlValue)
xmlValue
xmlValue()
xpathSApply(html, "//td[@id='col-citedby']", xmlValue)
html
xpathSApply(html, "//td[@id='col-citedby']", xmlValue)
xpathSApply(html, "//td[@class='gsc_a_c']", xmlValue)
library(httr)
html2 = GET(url)
url
html2 = GET(url)
html2
library(htt4)
library(httr)
html2 = GET(url)
html2 = GET(url="http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
str_detect
str_detect()
url = "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
library(httr)
install.packages(httr)
library(stringi)
install.packages(stringi)
install.packages("httr")
html2 = GET(url)
library(httr)
install.packages("devtools")
library(httr)
install.packages("stringi")
html2 = GET(url)
library(httr)
html2 = GET(url)
html2
parsedHtml = html.Parse(content2, asTest=T)
content2 = content(html2, as="text")
parsedHtml = html.Parse(content2, asTest=T)
library(html)
parsedHtml = htmlParse(content2, asTest=T)
library(htmlParse)
library(htmlTools)
library(htmltools)
parsedHtml = htmlParse(content2, asTest=T)
library(htmlparse)
install.packages(htmlparse)
install.packages(htmlparser)
install.packages(htmltools)
install.packages(XML)
library(XML)
parsedHtml = htmlParse(content2, asTest=T)
parsedHtml = htmlParse(content2, asText=T)
parsedHtml
xpathSApply(parsedHtml, "//title", xmlValue)
pg1= GET("http://httpbin.org/basic-auth/user/passwd")
pg1
pg2= GET("http://httpbin.org/basic-auth/user/passwd", authenticate("user", "passwd"))
pg2
names(pg2)
google=handle("http://google.com")
pg1 = GET(handle=google, path="/")
pg2 = GET(handle = google, path="search")
pg1
pg2
myapp = oauth_app("twitter", key="oXmMpRvjORzhZOKQ0TXYMHoiu", secret="MB4OuzN4J0RYcbJ7vzVtH5fasYZsdUdKeeTZBo2DKwhsxPbCID")
sig = sign_oauth1.0(myapp, token = "128415105-8muWgjkToWBVbdKV3o5PEU7LpyNsXibrqnZZbzJl", token-secret="7LHkrVOmvIDeLgFjVZZDLLFNpribNuTcH03L0RqabeD4m")
sig = sign_oauth1.0(myapp, token = "128415105-8muWgjkToWBVbdKV3o5PEU7LpyNsXibrqnZZbzJl", token_secret="7LHkrVOmvIDeLgFjVZZDLLFNpribNuTcH03L0RqabeD4m")
homeTL = GET("https://api.twitter.com/1.1/statuses/home_timeline.json", sig)
homeTL
install.packages(base64enc)
library(base64enc)
library("base64enc"")
library("base64enc)
library("base64enc")
homeTL = GET("https://api.twitter.com/1.1/statuses/home_timeline.json", sig)
install.packages("httr")
install.packages("httr")
install.packages("httr")
install.packages("httr")
install.packages("httr")
install.packages("httr")
setwd(paste(Sys.getenv("USERPROFILE"), "\\Documents\\GitHub\\ProgrammingAssignment_cleandata\\getdata_projectfiles_UCI HAR Dataset\\UCI HAR Dataset", sep=""))
x_test <- read.csv("test\\x_test.txt", stringsAsFactors = F, header=F, sep=" ", strip.white = T, numerals ="no.loss")
y_test <- read.csv("test\\y_test.txt", stringsAsFactors = F, header=F, sep=" ")
x_test
head(x_test, 1)
str(x_test)
x_test$V3
str(x_test)
summary(x_test)
x_test <- read.csv("test\\x_test.txt", stringsAsFactors = F, header=F, numerals ="no.loss")
str(x_test)
head(x_test, 1)
head(x_test, 2)
?"data.frame"
source('~/GitHub/ProgrammingAssignment_cleandata/run_analysis.R')
x_test <- read.csv("test\\x_test.txt", stringsAsFactors = F, header=F, numerals ="no.loss")
x_train <- read.csv("train\\x_train.txt", stringsAsFactors = F, header=F, numerals ="no.loss")
y_test <- read.csv("test\\y_test.txt", stringsAsFactors = F, header=F)
y_train <- read.csv("train\\y_train.txt", stringsAsFactors = F, header=F)
?merge
merge(x_test, x_train)
?append
str(x_test)
?read.csv
x_test <- read.csv("test\\x_test.txt", stringsAsFactors = F, header=F, sep=" ", numerals ="no.loss")
x_test <- read.csv("test\\x_test.txt", stringsAsFactors = F, header=F, sep=" ", numerals ="no.loss", blank.lines.skip=T)
source('~/GitHub/ProgrammingAssignment_cleandata/run_analysis.R')
x_test <- read.csv("test\\x_test.txt", stringsAsFactors = F, header=F, sep=" ", numerals ="no.loss")
x_test$V1
x_test <- read.csv("test\\x_test.txt", stringsAsFactors = F, header=F, sep=" ", strip.white=T, numerals ="no.loss")
x_test$V1
head(x_test, 1)
?tapply
?melt
library(plyr)
?melt
?"plyr"
?as.integer
?names
library(reshape2)
?dcast
?na.omit
x_test_clean <- na.omit(x_test)
head(x_test_clean)
head(x_test, 1)
DF <- data.frame(x = c(1, 2, 3), y = c(0, 10, NA))
na.omit(DF)
na.omit(DF)
DF
DF <- null
remove(DF)
?na
?is.na
head(x_test, 1)
str(x_test)
x_test1 <- x_test[1]
View(x_test1)
x_test1_clean <- x_test1[!is.na(s_test1)]
x_test1_clean <- x_test1[!is.na(x_test1)]
x_test1_clean
head(x_test, 1)
?read.table
source('~/GitHub/ProgrammingAssignment_cleandata/run_analysis.R')
source('~/GitHub/ProgrammingAssignment_cleandata/run_analysis.R')
source('~/GitHub/ProgrammingAssignment_cleandata/run_analysis.R')
x_test <- read.csv("test\\x_test.txt", stringsAsFactors = F, header=F, sep="", numerals ="no.loss")
head(x_test)
x_test <- read.csv("test\\x_test.txt", stringsAsFactors = F, header=F, sep="", numerals ="no.loss")
x_train <- read.csv("train\\x_train.txt", stringsAsFactors = F, header=F, sep="", numerals ="no.loss")
y_test <- read.csv("test\\y_test.txt", stringsAsFactors = F, header=F, sep="")
y_train <- read.csv("train\\y_train.txt", stringsAsFactors = F, header=F, sep="")
remove(x_test1)
remove(x_test_clean)
remove(x_test1_clean)
x_merged <- merge(x_test, x_train)
str(x_merged)
features <- read.csv("features.txt", header=F, stringsAsFactors = F, sep=" ")
subject_test <- read.csv("test\\subject_test.txt", stringsAsFactors = F, header=F)
str(features)
source('~/GitHub/ProgrammingAssignment_cleandata/run_analysis.R')
cols <- features$V2
?colnames<-
?colnames
?names
names(x_test)
len (cols)
names(x_test) <- cols
names(x_test)
str(x_test)
View(x_test)
names(x_train) <- cols
x_merged <- rbind(x_train, x_test)
source('~/GitHub/ProgrammingAssignment_cleandata/run_analysis.R')
features <- read.csv("features.txt", header=F, stringsAsFactors = F, sep=" ")
cols <- features$V2   # only grab the second column - it contains all the column names for our x datasets
subject_test <- read.csv("test\\subject_test.txt", stringsAsFactors = F, header=F)
x_test <- read.csv("test\\x_test.txt", stringsAsFactors = F, header=F, sep="", numerals ="no.loss")
x_train <- read.csv("train\\x_train.txt", stringsAsFactors = F, header=F, sep="", numerals ="no.loss")
y_test <- read.csv("test\\y_test.txt", stringsAsFactors = F, header=F, sep="")
y_train <- read.csv("train\\y_train.txt", stringsAsFactors = F, header=F, sep="")
x_merged <- rbind(x_train, x_test)
y_merged <- rbind(y_train, y_test)
names(x_merged) <- cols
View(y_train)
View(y_test)
View(y_train)
View(y_merged)
setwd(paste(Sys.getenv("USERPROFILE"), "\\Documents\\GitHub\\ProgrammingAssignment_cleandata\\getdata_projectfiles_UCI HAR Dataset\\UCI HAR Dataset", sep=""))
measurements <- read.csv("features.txt", header=F, stringsAsFactors = F, sep=" ")
measurement_cols <- features$V2   # only grab the second column - it contains all the column names for our measurements
subject <- read.csv("test\\subject_test.txt", stringsAsFactors = F, header=F)
activities <- read.csv("activity_labels.txt", header=F, stringsAsFactors = F, sep=" ")
activity_cols <- activities$V2   # only grab the second column - it contains all the column names for our activities
x_test <- read.csv("test\\x_test.txt", stringsAsFactors = F, header=F, sep="", numerals ="no.loss")
x_train <- read.csv("train\\x_train.txt", stringsAsFactors = F, header=F, sep="", numerals ="no.loss")
y_test <- read.csv("test\\y_test.txt", stringsAsFactors = F, header=F, sep="")
y_train <- read.csv("train\\y_train.txt", stringsAsFactors = F, header=F, sep="")
x_merged <- rbind(x_train, x_test)
y_merged <- rbind(y_train, y_test)
names(x_merged) <- measurement_cols
names(y_merged) <- activity_cols
fulldata <- cbind(subject, y_merged, x_merged)
str(y_merged)
activity_cols
activities
measurement_cols
str(y_merged)
str(activity_cols)
str(measurement_cols)
y_merged
names(y_merged) <- activity_cols
names(y_merged)
y_merged
fulldata <- cbind(subject, y_merged, x_merged)
str(subject)
str(y_merged)
str(x_merged)
source('~/GitHub/ProgrammingAssignment_cleandata/run_analysis.R')
# 1.Merges the training and the test sets to create one data set.
setwd(paste(Sys.getenv("USERPROFILE"), "\\Documents\\GitHub\\ProgrammingAssignment_cleandata\\getdata_projectfiles_UCI HAR Dataset\\UCI HAR Dataset", sep=""))
measurements <- read.csv("features.txt", header=F, stringsAsFactors = F, sep=" ")
measurement_cols <- features$V2   # only grab the second column - it contains all the column names for our measurements
activities <- read.csv("activity_labels.txt", header=F, stringsAsFactors = F, sep=" ")
activity_cols <- activities$V2   # only grab the second column - it contains all the friendly names for our activities
#read in the x, y, and subject data sets for train and test
x_train <- read.csv("train\\x_train.txt", stringsAsFactors = F, header=F, sep="", numerals ="no.loss")
x_test <- read.csv("test\\x_test.txt", stringsAsFactors = F, header=F, sep="", numerals ="no.loss")
y_train <- read.csv("train\\y_train.txt", stringsAsFactors = F, header=F, sep="")
y_test <- read.csv("test\\y_test.txt", stringsAsFactors = F, header=F, sep="")
subject_train <- read.csv("train\\subject_train.txt", stringsAsFactors = F, header=F)
subject_test <- read.csv("test\\subject_test.txt", stringsAsFactors = F, header=F)
# combine the train and test data sets for x, y, and subject
x_merged <- rbind(x_train, x_test)
y_merged <- rbind(y_train, y_test)
subject_merged <- rbind(subject_train, subject_test)
names(x_merged) <- measurement_cols
#        names(y_merged) <- activity_cols
fulldata <- cbind(subject, y_merged, x_merged)
source('~/GitHub/ProgrammingAssignment_cleandata/run_analysis.R')
names(x_merged) <- measurement_cols
source('~/GitHub/ProgrammingAssignment_cleandata/run_analysis.R')
measurement_cols <- measurements$V2   # only grab the second column - it contains all the column names for our measurements
names(x_merged) <- measurement_cols
fulldata <- cbind(subject_merged, y_merged, x_merged)
head(fulldata, 1)
names(y_merged) <- "activites"
head(fulldata, 1)
head(subject_merged, 1)
source('~/GitHub/ProgrammingAssignment_cleandata/run_analysis.R')
names(y_merged) <- "activity"
names(subject_merged) <- "subject"
fulldata <- cbind(subject_merged, y_merged, x_merged)
head(fulldata, 1)
names(fulldata)
?contains
?substr
?grep
col_names <- names(fulldata)
col_names
col_names[grep("mean|std", col_names, value = F)]
col_names[grep("mean|std", col_names, value = F)]
grep("mean|std", col_names, value = F)
c(1, 2, mean_std_cols)
c(1, 2, grep("mean|std", col_names, value = F))
mean_std_cols <- grep("mean|std", col_names, value = F)
mean_std_data = fulldata[c(1, 2, mean_std_cols)]
head(mean_std_data)
activities
?str_sub
?factor
factor(mean_std_data$activity, levels=activites)
factor(mean_std_data$activity, levels=activities)
mean_std_data$activity
activities
?merge
?map
merge(mean_std_data, activities)
merge(mean_std_data, activities, by.x="activity", by.y="V1")
fail <- merge(mean_std_data, activities, by.x="activity", by.y="V1")
str(fail)
str(mean_std_data)
source('~/GitHub/ProgrammingAssignment_cleandata/run_analysis.R')
fail <- merge(mean_std_data, activities, by.x="activity", by.y="V1", sort=F)
head(fail, 1)
head(fail)
head(fail, 30)
head(fail, 50)
head(fail, 100)
head(fail, 50)
head(mean_std_data, 30)
activities
names(activities) <- c("id", "activity")
activities
source('~/GitHub/ProgrammingAssignment_cleandata/run_analysis.R')
names(activities) <- c("id", "name")
activities
remove(fail)
activities$name[activities$id == mean_std_data$activity]
activities$id
mean_std_data$activity
activities$name[mean_std_data$activity]
test<-activities$name[mean_std_data$activity]
head(test)
head(test, 50)
mean_std_data$activity <- activities$name[mean_std_data$activity]
head(mean_std_data)
head(mean_std_data, 40)
View(mean_std_data)
str(mean_std_data)
?group_by
library(dplyr)
?group_by
?summarize_each
?summarise_each
?%>%
View(mean_std_data)
mean_std_data %>% group_by("subject", "activity")
test <- mean_std_data %>% group_by("subject", "activity")
head(test, 40)
test
test <- mean_std_data %>% group_by("subject", "activity") %>% summarise_each(funs(mean))
test2 <- mean_std_data %>% group_by("subject", "activity") %>% summarise_each(funs(mean))
test2 <- mean_std_data %>% group_by(subject, activity) %>% summarise_each(funs(mean))
View(test2)
source('~/GitHub/ProgrammingAssignment_cleandata/run_analysis.R')
run_analysis()
source('~/GitHub/ProgrammingAssignment_cleandata/run_analysis.R')
run_analysis()
# 1.Merges the training and the test sets to create one data set.
setwd(paste(Sys.getenv("USERPROFILE"), "\\Documents\\GitHub\\ProgrammingAssignment_cleandata\\getdata_projectfiles_UCI HAR Dataset\\UCI HAR Dataset", sep=""))
measurements <- read.csv("features.txt", header=F, stringsAsFactors = F, sep=" ")
measurement_cols <- measurements$V2   # only grab the second column - it contains all the column names for our measurements
activities <- read.csv("activity_labels.txt", header=F, stringsAsFactors = F, sep=" ")
activity_names <- activities$V2   # only grab the second column - it contains all the friendly names for our activities
#read in the x, y, and subject data sets for train and test
x_train <- read.csv("train\\x_train.txt", stringsAsFactors = F, header=F, sep="", numerals ="no.loss")
x_test <- read.csv("test\\x_test.txt", stringsAsFactors = F, header=F, sep="", numerals ="no.loss")
y_train <- read.csv("train\\y_train.txt", stringsAsFactors = F, header=F, sep="")
y_test <- read.csv("test\\y_test.txt", stringsAsFactors = F, header=F, sep="")
subject_train <- read.csv("train\\subject_train.txt", stringsAsFactors = F, header=F)
subject_test <- read.csv("test\\subject_test.txt", stringsAsFactors = F, header=F)
# combine the train and test data sets for x, y, and subject
x_merged <- rbind(x_train, x_test)
y_merged <- rbind(y_train, y_test)
subject_merged <- rbind(subject_train, subject_test)
# 4. Appropriately labels the data set with descriptive variable names.
names(x_merged) <- measurement_cols
names(y_merged) <- "activity"
names(subject_merged) <- "subject"
# combine subject, activity, and measurements into one dataset
fulldata <- cbind(subject_merged, y_merged, x_merged)
# 2. Extracts only the measurements on the mean and standard deviation for each measurement.
col_names <- names(fulldata)
#indices of the columns which have the word "mean" or "std" in them (does not include vectors with "Mean" in the name used in angle() variable - see features_info.txt)
mean_std_cols <- grep("mean|std", col_names, value = F)
mean_std_data = fulldata[c(1, 2, mean_std_cols)]
# 3. Uses descriptive activity names to name the activities in the data set
mean_std_data$activity <- activities$name[mean_std_data$activity]
# 5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
tidy_data <- mean_std_data %>% group_by(subject, activity) %>% summarise_each(funs(mean))
View(mean_std_data)
View(activities)
View(fulldata)
View(fulldata)
View(mean_std_data)
source('~/GitHub/ProgrammingAssignment_cleandata/run_analysis.R')
# 1.Merges the training and the test sets to create one data set.
setwd(paste(Sys.getenv("USERPROFILE"), "\\Documents\\GitHub\\ProgrammingAssignment_cleandata\\getdata_projectfiles_UCI HAR Dataset\\UCI HAR Dataset", sep=""))
measurements <- read.csv("features.txt", header=F, stringsAsFactors = F, sep=" ")
measurement_cols <- measurements$V2   # only grab the second column - it contains all the column names for our measurements
activities <- read.csv("activity_labels.txt", header=F, stringsAsFactors = F, sep=" ")
#read in the x, y, and subject data sets for train and test
x_train <- read.csv("train\\x_train.txt", stringsAsFactors = F, header=F, sep="", numerals ="no.loss")
x_test <- read.csv("test\\x_test.txt", stringsAsFactors = F, header=F, sep="", numerals ="no.loss")
y_train <- read.csv("train\\y_train.txt", stringsAsFactors = F, header=F, sep="")
y_test <- read.csv("test\\y_test.txt", stringsAsFactors = F, header=F, sep="")
subject_train <- read.csv("train\\subject_train.txt", stringsAsFactors = F, header=F)
subject_test <- read.csv("test\\subject_test.txt", stringsAsFactors = F, header=F)
# combine the train and test data sets for x, y, and subject
x_merged <- rbind(x_train, x_test)
y_merged <- rbind(y_train, y_test)
subject_merged <- rbind(subject_train, subject_test)
# 4. Appropriately labels the data set with descriptive variable names.
names(x_merged) <- measurement_cols
names(y_merged) <- "activity"
names(subject_merged) <- "subject"
names(activities) <- c("id", "names")
# combine subject, activity, and measurements into one dataset
fulldata <- cbind(subject_merged, y_merged, x_merged)
# 2. Extracts only the measurements on the mean and standard deviation for each measurement.
col_names <- names(fulldata)
#indices of the columns which have the word "mean" or "std" in them (does not include vectors with "Mean" in the name used in angle() variable - see features_info.txt)
mean_std_cols <- grep("mean|std", col_names, value = F)
mean_std_data = fulldata[c(1, 2, mean_std_cols)]
# 3. Uses descriptive activity names to name the activities in the data set
mean_std_data$activity <- activities$name[mean_std_data$activity]
# 5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
tidy_data <- mean_std_data %>% group_by(subject, activity) %>% summarise_each(funs(mean))
View(tidy_data)
write.table(tidy_data, "tidy.txt", row.names = FALSE)
source('~/GitHub/ProgrammingAssignment_cleandata/run_analysis.R')
source('~/GitHub/ProgrammingAssignment_cleandata/run_analysis.R')
run_analysis()
source('~/GitHub/ProgrammingAssignment_cleandata/run_analysis.R')
